<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Ai | @Lenciel]]></title>
  <link href="http://lenciel.com/blog/categories/ai/atom.xml" rel="self"/>
  <link href="http://lenciel.com/"/>
  <updated>2016-04-05T22:35:07+08:00</updated>
  <id>http://lenciel.com/</id>
  <author>
    <name><![CDATA[Lenciel Li]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[人工智能，奇点及其他(二)]]></title>
    <link href="http://lenciel.com/2016/03/alphago-ai-part2/"/>
    <updated>2016-03-20T16:01:14+08:00</updated>
    <id>http://lenciel.com/2016/03/alphago-ai-part2</id>
    <content type="html"><![CDATA[<p><a href="http://lenciel.com/2016/03/alphago-and-ai/">上一篇</a>留下了几个问题：</p>

<ul>
<li>人工智能和人类智慧究竟有没有一点点可比性？</li>
<li>如果有，究竟发展到什么阶段了呢？</li>
<li>既然发展到这里了，奇点到底存不存在？人类要不要完呢？</li>
</ul>


<p>人类有这些疑问是自然而然的，特别是人工智能目前由“认知派”扛大旗：既然是模拟大脑的工作原理，难免就要被拿来和大脑本身的机能做比较。</p>

<p>本座谨慎地尝试一下从窘迫了几十年的“认知派”们为了科研经费发明的各种古里古怪的名词里面（比如因为AlphaGo蹿红的“深度学习”，就是辛顿在多年的神经网络研究受冷遇好不容易化到缘之后搞出来的新瓶装旧酒的词）脱身，站在更高层面上来回答一下这些问题。</p>

<a name="L..........................."></a>
<h3>人工智能和人类智慧</h3>

<p>目前显然是没有什么可比性的。</p>

<p>不说直觉，情感等等，就拿学习能力来说，李世乭在几盘对弈里面各种充满策略的尝试，还没有机器能完成：人类如何通过极少的样本迅速地提升对本来未知领域的学习能力，还是个谜。</p>

<p>那为什么很多比我们靠近前沿的专家对如此羸弱的人工智能忧心忡忡呢？</p>

<p>这很大程度上是基于人类科技发展速度的一个推断。</p>

<p>比如这两天刘诗诗和吴奇隆结婚画面太感人，本座看到微信评论里面有一条“想穿越回清朝去见见四阿哥”被顶了几千次。</p>

<p>不知道迷恋这类穿越戏码的人有没有想过一个问题：如果把社会把他/她作为神接受的程度叫做”装神认可度”，在时间轴上不同年代的人，要达到类似神的地位，需要往前穿越多少年？</p>

<p>比如从现代穿回清代，召集当时社会最聪明的100个人，要用什么来证明自己是神呢？可控核聚变、相对论还是引力波？是不是手机就够了？要不飞机地铁？或者国家电网？</p>

<p>在人类生活的方方面面，可以说出各种东西把当时最聪明的人骇到瞠目结舌。</p>

<p>那么如果是一个清代的人要刷到相同的装神认可度，需要往前穿越多久呢？</p>

<p>如果穿的时间距离差不多，到元明这些时候，那么还是在封建社会，可能并没有办法当神。但如果来到刀耕火种的农业社会，比如夏商周，只需要表演一次九九乘法表，可能性就会大大增加。</p>

<p>那么如果是一个商朝的人要获得相同的装神接受度，需要往前穿越多久呢？</p>

<p>大概穿越到石器时代都不太够，可能得往公元前几十万年还不会好好保存火的年代去了。</p>

<p>这种装神接受度的剧烈变化，说明了两个问题：</p>

<ol>
<li>人类的进化过程是非常缓慢的</li>
<li>人类科技发展是具有加速度的</li>
</ol>


<p>上篇提到过的明斯基的高徒，也是奇点理论的宣传者<a href="https://zh.wikipedia.org/wiki/%E9%9B%B7%E8%92%99%E5%BE%B7%C2%B7%E5%BA%93%E8%8C%A8%E9%AD%8F%E5%B0%94">库兹韦尔</a>的预测是：人类在2000到2020年20年间的科技发展成就，要相当于前面2000年的总和。</p>

<p>也正是在“科技在以很大的加速度发展，人类自己的进化却非常缓慢”这样所有人都容易认可的理论支撑下，人工智能的威胁才被很多主流科学家拿出来讨论：他们觉得作为提供加速度的一方，还是有必要提醒一下缓慢的一方。</p>

<p>比如斯蒂芬·霍金就说过：</p>

<p><blockquote><p>一旦发展出相当于或者超越人类智慧的人工智能技术，它（人工智能）就会脱离控制，以不断加快的速度重新设计自己。但是人类受到缓慢生物进化的限制，无法与其竞争，甚至可能最终被超越。</p></blockquote></p>

<p>那么，这种虽然现在还很蠢，但进化得超快的东西，究竟要多久超越我们呢？</p>

<a name="L..........................."></a>
<h3>人工智能的发展阶段</h3>

<p>和那些科幻片里面自以为是最后遭遇灭顶之灾的人类一样，我们早就给“人工智能”的发展划分了严格的阶段：</p>

<ul>
<li>Artificial Narrow Intelligence (ANI)</li>
<li>Artificial General Intelligence (AGI)</li>
<li>Artificial Superintelligence (ASI)</li>
</ul>


<a name="ANI"></a>
<h4>ANI</h4>

<p>指能够有效处理的问题域有局限的AI，在很多文章里面也被称为<code>Weak AI</code>：除开下围棋下赢李世乭，其实我们每天的生活里面也充满了ANI：</p>

<ul>
<li>你的手机里面有siri这样的个人助手，有网易云音乐这种可以给你推荐你喜爱风格歌曲的音乐程序等等ANI系统</li>
<li>当你在京东上搜了情趣内衣，你上其他网站的时候老是有情趣小窗弹出来：广告系统里面也到处都是ANI</li>
<li>Google的在线翻译，微信的语音识别，Soundcloud的你哼它猜，凡此种种都是ANI</li>
<li>但你其实连不上Google，因为GFW也是用ANI在<a href="http://arxiv.org/abs/1603.04865">识别加密流量</a>啊</li>
<li>你觉得烦，扔掉电脑和手机，开车出门：车里面的ANI系统更多了，什么ABS，什么智能省油，而且，车都快不需要你开了你也知道吧</li>
</ul>


<p>如果我们仅仅处于ANI里面，好像也无伤大雅。甚至可能有些开心：因为机器做了枯燥的事情，我们则去处理需要创意的部分。</p>

<p> Vernor Vinge, 1993<a href="https://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html">里面</a>说过：</p>

<p><blockquote><p>We are on the edge of change comparable to the rise of human life on Earth.</p></blockquote></p>

<p>这个变化，就是从ANI到AGI的变化。</p>

<a name="AGI"></a>
<h4>AGI</h4>

<p>AGI，在AlphaGo的总结里面也<a href="https://googleblog.blogspot.hk/2016/03/what-we-learned-in-seoul-with-alphago.html">提到了</a>，很多文章里面也被称为<code>Strong AI</code>，Linda Gottfredson对它有个比较正式的定义：</p>

<p><blockquote><p>A very general mental capability that, among other things, involves the ability to reason, plan, solve problems, think abstractly, comprehend complex ideas, learn quickly, and learn from experience.</p></blockquote></p>

<p>从ANI到AGI，难点在哪里？为什么计算，策略，语言翻译等等，对电脑来说越来越容易；视觉，感觉，运动，和预测，对电脑来说仍然很难？</p>

<p>Knuth老爹的评价最好懂：</p>

<p><blockquote><p>AI has by now succeeded in doing essentially everything that requires ‘thinking’ but has failed to do most of what people and animals do ‘without thinking.&lsquo;</p></blockquote></p>

<p>的确，我们对自己的大脑是如何工作的本来就不清楚。当我们伸手去撩妹的时候，这么个看起来不需要“过脑”的动作，其实是需要肌肉，神经，骨骼由大脑统一指挥，由几百万年进化形成的复杂系统配合完成的。对于计算机来说，如果看不准，或者力道控制不好，可能撩出骨髓穿刺等各种令人遗憾的效果。</p>

<p>即像“看准”，“捏稳”等等范畴的问题解决了，那也只是“认识世界”，要达到人类的智力水平，更难的事情摆在后面：感受世界。</p>

<p>高兴、满意、解脱和苟且要如何区别？眉来眼去之后要不要跟一个欲说还休？《霸王别姬》比《霸王硬上弓》好在哪里？</p>

<a name="L...ANI...AGI"></a>
<h4>从ANI到AGI</h4>

<p>看起来如此遥不可及的目标，靠人类科技的大爆发怎么到达？</p>

<a name="L.................."></a>
<h5>计算能力爆炸</h5>

<p>科学家认为人类大脑的计算能力是每秒10的16次方这个量级的。</p>

<p>确实很变态，但其实已经有一台计算机已经超越了这个数字：那就是中国国防科大研制的<a href="https://www.zhihu.com/question/21217971">天河二</a>。</p>

<p>当然，造价一亿美金，占地720平方米，24兆瓦功耗（满配跑一年电费1.5亿人民币）不是一个很容易接受的超越方式对不对？</p>

<p>但不要忘了摩尔定律：假设计算能力会以每十年便宜100倍的速度降价，所以高高在上的模拟人脑需要的计算能力，很快就不是问题了。</p>

<a name="L..............."></a>
<h4>更巧妙的解</h4>

<p>AI Caliber 2) Artificial General Intelligence (AGI): Sometimes referred to as Strong AI, or Human-Level AI, Artificial General Intelligence refers to a computer that is as smart as a human across the board—a machine that can perform any intellectual task that a human being can. Creating AGI is a much harder task than creating ANI, and we’re yet to do it. Professor Linda Gottfredson describes intelligence as “a very general mental capability that, among other things, involves the ability to reason, plan, solve problems, think abstractly, comprehend complex ideas, learn quickly, and learn from experience.” AGI would be able to do all of those things as easily as you can.</p>

<p>AI Caliber 3) Artificial Superintelligence (ASI): Oxford philosopher and leading AI thinker Nick Bostrom defines superintelligence as “an intellect that is much smarter than the best human brains in practically every field, including scientific creativity, general wisdom and social skills.” Artificial Superintelligence ranges from a computer that’s just a little smarter than a human to one that’s trillions of times smarter—across the board. ASI is the reason the topic of AI is such a spicy meatball and why the words “immortality” and “extinction” will both appear in these posts multiple times.</p>

<a name="L.................................ANI"></a>
<h4>目前的阶段：世界已经被ANI</h4>

<p>在特定的问题域，机器已经远远超过了人类，因此我们日常生活中遍布着ANI：</p>

<a name="L......"></a>
<h3>奇点</h3>

<p>Secondly, you’ve probably heard the term “singularity” or “technological singularity.” This term has been used in math to describe an asymptote-like situation where normal rules no longer apply. It’s been used in physics to describe a phenomenon like an infinitely small, dense black hole or the point we were all squished into right before the Big Bang. Again, situations where the usual rules don’t apply. In 1993, Vernor Vinge wrote a famous essay in which he applied the term to the moment in the future when our technology’s intelligence exceeds our own—a moment for him when life as we know it will be forever changed and normal rules will no longer apply. Ray Kurzweil then muddled things a bit by defining the singularity as the time when the Law of Accelerating Returns has reached such an extreme pace that technological progress is happening at a seemingly-infinite pace, and after which we’ll be living in a whole new world. I found that many of today’s AI thinkers have stopped using the term, and it’s confusing anyway, so I won’t use it much here (even though we’ll be focusing on that idea throughout).</p>

<p>站在历史的进程里面，如果是大牛的视线是这样的：</p>

<p>而≤</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[人工智能，奇点及其他(一)]]></title>
    <link href="http://lenciel.com/2016/03/alphago-and-ai/"/>
    <updated>2016-03-15T02:59:42+08:00</updated>
    <id>http://lenciel.com/2016/03/alphago-and-ai</id>
    <content type="html"><![CDATA[<p><img src="/downloads/images/2016_03/go_ai.png" title="Don't touch me..." alt="Vhost threshold" /></p>

<p>3月14日，是个很魔性的日子：这天是爱因斯坦的生日，也是卡尔马克思的忌日，还是“π日&#8221;——纪念圆周率弄的“数学节&#8221;，忒魔性。</p>

<p>虽然同一天是巧合，但马克思主义、广义相对论和数学真的有一个共性：它们都在人类社会被广泛地讨论，反复地消费，但真正明白它们的人类非常少。</p>

<p>当然，多年之后回看2016年的这天，大概不会找到关于上面几样东西的太多痕迹：因为AlphaGo和李世乭的对弈，大家都讨论人工智能呢。</p>

<p>在朋友圈或者小网站满天飞的段子里，严肃媒体纷纷跟进匆忙写就的报道里，以及少数科学家对未来的惊世骇俗的预测里，人工智能的进展被<a href="http://chuansong.me/n/1933903">大大神话</a>了。</p>

<p>而在专业圈子里面，不知道是因为看到小白们纷纷讨论科学问题感到不屑一顾，还是对媒体没把自己研究的领域大肆报道感到呼吸不畅，人工智能的进展又被一些人<a href="http://www.yinwang.org/blog-cn/2016/03/09/alpha-go">大大地</a><a href="http://hunch.net/?p=3692542">低估</a>了。</p>

<p>而本座多少也算接触过人工智能：当年导师第一次关怀小弟，就扔我去实现一个基于网格计算的象棋程序。项目虽然失败了，却也激发了本座写代码的兴趣。自动化系的所有课程，优化相关的我还算有点儿兴趣，毕业后一有机会也都喜欢实现算法来玩玩：去年参加基友组织的2048编程比赛，正好还仔细读过台湾道友的一个使用了蒙特卡洛树搜索的实现。</p>

<p>所以虽然并不太懂，也想结合自己知道的，为避免人工智能变成下一个被广泛讨论反复消费，但真正明白的人太少的话题，尽一份普通人的力量。</p>

<a name="L............"></a>
<h3>人工智能</h3>

<p>当我们说人工智能的时候，我们在说什么，对不同的人来说很不一样。</p>

<p>比如这是我的老同学，现在从事无人系统教学和研究的李教授在朋友圈里面的一段话：</p>

<p><blockquote><p>α狗的表现说明了在深度网络的帮助下，多步策略优化已经可以被数据驱动得很不错了。自从两年前nature 上发表了将深度网络与增强学习结合的工作，就可以预见这一天很快到来。不过，要说这是人工智能的伟大胜利，可能有些牵强。这种有准确问题表示并且规则清晰的搜索任务，算不算人工智能估计还得另说呢。非要说人类能力干不过就算牛，那么在干微分方程数值解等任务上，计算机早就甩我们一百条街了。神话下棋计算机的估计有两类人，一是不太懂行的科普作家，二是准备骗人的商家。当年一个傅立叶变换都能包装成各种包治百病的“x林频谱仪&#8221;，还有什么是不可能的？</p></blockquote></p>

<p>可以说老李的出发点和本座灌这篇水的意图类似，说的内容我也觉得很赞。唯独“这种有准确问题表示并且规则清晰的搜索任务，算不算人工智能估计还得另说呢&#8221;，让我想起来人工智能奠基人之一麦卡锡当年的娇嗔：</p>

<p><blockquote><p>As soon as it works, no one calls it AI.</p></blockquote></p>

<p>也就是说，虽然人工智能相关的技术我们每天都在大量使用，但因为执行端是电脑，而电脑能够执行的仍然是表达算法的代码，所以一个人工智能的问题一旦被解决，就变成了一个算法，没有人认为它是人工智能了。</p>

<p>那么人工智能究竟是什么呢？</p>

<a name="L........................"></a>
<h4>学术界的人工智能</h4>

<p>治学先治史。</p>

<p>人工智能的奠基，公认是在60年前的<a href="https://zh.wikipedia.org/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE">达特茅斯会议</a>，原因之一是会议的正式名字：“人工智能夏季研讨会” (Summer Research Project on Artificial Intelligence)，据考证这是Artificial Intelligence首次被正式公开使用。叫这么玄幻主要是大会的经费需要找洛克菲勒基金会申请：目的并没有完全达到，$13500的预算被批准了$7500。</p>

<p>但这次花销略低于国企普通招待晚宴的会议产生的影响却是深远的，我们只需要看看与会者他们人生轨迹的变化：</p>

<p>香农（C. E. Shannon）：信息论的奠基人不用介绍了，当时已经是贝尔实验室大佬的香农，是因为和图灵交流后对计算机下棋有了兴趣（在1949年和1950年他发表了<a href="https://chessprogramming.wikispaces.com/Claude+Shannon">两篇讲计算机下棋</a>的文章），还是被拉去当腰封的，现在很难弄清了：总之这会议对香老爷产生的影响不大。</p>

<p>但有四个人后来拿了图灵奖：</p>

<ul>
<li><p>明斯基（M. Minsky）：普林斯顿数学系主任塔克（Tucker）的学生（他带Minsky之前带的就是纳什），后来公认的<a href="http://china.caixin.com/2016-03-14/100919927.html">人工智能之父</a>。2013年接替吴恩达，出任Google Brain项目负责人的，奇点理论的宣传者和知名未来学家<a href="https://zh.wikipedia.org/wiki/%E9%9B%B7%E8%92%99%E5%BE%B7%C2%B7%E5%BA%93%E8%8C%A8%E9%AD%8F%E5%B0%94">库兹韦尔</a>(R. Kurzweil)就是他的学生。当时在哈佛大学数学与神经学做初级研究员的他，被麦卡锡拉到MIT的MAC项目里，作为AI实验室的同事。孕育出UNIX的Multics，其中的分时系统的设计就是明斯基和麦卡锡一起捣鼓出来的</p></li>
<li><p>麦卡锡（J. McCarthy）：在普林斯顿数学系博士毕业后，受师兄Kemeny（没错，就是图灵的师弟，费曼的同事，爱因斯坦的数学助理，Basic语言的发明人，后来混进总统智囊团的Kemeny）的提携，去了达特茅斯学院做数学系助教。包括图灵奖在内的奖拿了一堆，离开达特茅斯学院之后，先后领导了MIT和Stanford两个学校的AI实验室，并且让两个实验室友好对战了很多年。不那么公认的<a href="http://tech.sina.com.cn/it/2011-10-25/07446225013.shtml">人工智能之父</a>，但因为是LISP语言的发明者而享誉码农圈数十载。</p></li>
<li><p>纽厄尔（A. Newell）：冯·诺伊曼的合作者、博弈论先驱摩根斯顿的学生。他和塞弗里奇在兰德认识之后，受后者模式识别和神经网络的影响很大，用不同的方法论做了很多相关的工作。被司马贺搞到卡耐基梅隆之后，一起开创了人工智能符号派，弄出了信息处理语言（IPL），并写了该语言最早的两个AI程序，也因此拿了图灵奖。</p></li>
<li><p>司马贺（H. A. Simon）：这位更是奇人。1943年芝加哥大学政治系毕业，1949年被卡耐基梅隆聘了之后研究了认知心理学、计算机科学、公共行政、经济学、管理学和科学哲学等多个方向。和纽厄尔一起拿了图灵奖之后3年，就跨界刷了个诺贝尔经济学奖。1972年作为第一批乒乓外交美方代表访华的时候主讲计算机科学，1980年第二次访华，主讲心理学，起了个中文名字司马贺。70多岁开始学汉语的他，1994年当选了中国科学院外籍院士。</p></li>
</ul>


<p>其他的参会者也非常了得：</p>

<ul>
<li><p>塞弗里奇（O. Selfridge）：名声没有前面这两位大，但其实是公认的模式识别之父，也做过一段时间明斯基的主管。他在MIT时一直和神经网络之父麦卡洛克（W. McCulloch）一起在维纳手下工作。维纳对他非常欣赏，《控制论》的第一个读者就是他，但因为没有写博士论文，所以没有拿到博士学位：这大概跟他出身有关，日不落帝国牛津街上的<a href="http://baike.baidu.com/view/9659397.htm">Selfridges</a>是他们家的</p></li>
<li><p>所罗门诺夫（R. Solomonoff）：1951年在芝加哥大学跟随费米得了物理硕士，就到了MIT的所罗门诺夫，没有大富大贵，但达特茅斯会议时，他受麦卡锡“反向图灵机”和乔姆斯基文法的启发，发明了“归纳推理机”，从而奠基了”算法信息论“。他的另一个观点“无限点”（Infinity Point）后来被未来学家库兹维尔改名“奇点”窃为己有</p></li>
<li><p>罗切斯特（N. Rochester）：IBM信息研究经理，IBM第一台商用计算机701机型设计者。作为一名计算机象棋研究者，他在IBM内部推动了很多人工智能研究，但是在董事会打压当时对这方面研究鼎力支持的主席Watson之后被搁置了。多年以后的今天，我们看到十八摸的救命稻草就是纪念这位主席的同名计算机认知系统<a href="http://www.ibm.com/smarterplanet/us/en/ibmwatson/ecosystem.html">Watson</a></p></li>
<li><p>撒缪尔（A. Samuel）：在IBM工作的真正的编程爱好者。使用701编写的跳棋程序是第一个具有学习能力的下棋程序，使用的就是现在被称为“α-β剪枝”的搜索。从IBM退休后去了Stanford执教，大量的时间都用来和Knuth搞Tex了。据说88岁生日的时候，都还在写程序</p></li>
</ul>


<p>整个人工智能研究的发展历史，其实是很值得国内建高校的人好好看看的。但是作为一名凡夫俗子，这里宛如奥斯卡红毯秀般铺陈星光熠熠的出场阵容，有几个目的：</p>

<ol>
<li><p>首先，可以看到，从人工智能奠基会上，就有三个人都是研究了“计算机下棋“的。下棋实在是一个贯穿人工智能这么多年历史的课题：这方面有个很好的资料网站是<a href="https://chessprogramming.wikispaces.com/">CPW</a></p></li>
<li><p>其次，我们搞不清人工智能研究范畴是很正常的。这次会议上定的七个研究课题是：</p>

<ul>
<li>可编程计算机</li>
<li>如何为计算机编程使其能够使用语言</li>
<li>神经网络</li>
<li>计算规模理论</li>
<li>机器学习</li>
<li>抽象</li>
<li>随机性与创造性</li>
</ul>


<p> 很明显如今看来，它的范围横跨了计算机、自动化、逻辑、数学、心理学等多个学科。实际上，这次会议之后，光是人工智能自己就分化出了”符号派“和”认知派“，两派惊心动魄的相爱相杀可以参考大牛尼克的<a href="http://blog.sina.com.cn/s/blog_71329a960102v1eo.html">神经网络简史</a>，或者是王飞跃老师<a href="http://china.caixin.com/2016-03-14/100919927.html">纪念明斯基的文章</a>（你看，纪念人工智能大佬的文章，是中国科学院自动化研究所的主任写的，足见”贵圈多乱“）</p></li>
<li><p>学术界的顶层圈子一直是很小的，或者说人类的顶层圈子一直是很小的，所以像你我这样的普通选手还是做做工程给下一代创造良好学习生活环境吧。且不说一个人工智能奠基会，台前幕后晃动的罗素、维纳、香农，就拿这次名震四海的DeepMind公司的大脑，神经网络的制霸辛顿来说，人家也是布尔（布尔代数的那个布尔）的后代。布尔一家为地球人哺育了各种人才，其中最邪门的应该是参与了抗战的初代毛粉<a href="http://baike.baidu.com/subview/1495132/13225597.htm">寒春</a>和<a href="http://baike.baidu.com/view/1981935.htm">韩丁</a>兄妹，最有名的应该是小说《牛虻》的作者伏尼契。当然，被《牛虻》的革命爱情感动得不行的几代中国人，可能不知道晚年入不敷出全靠周恩来特批的一笔稿费体面生活的伏尼契，其实生活在纽约</p></li>
<li><p>所有的东西到最后都是数学，学好它吧，孩儿们</p></li>
</ol>


<a name="L........................"></a>
<h4>普通人的人工智能</h4>

<p>都看到这儿了，我有点儿怀疑你到底是不是普通人。</p>

<p>因为普通人接触这个词主要是通过科幻电影和小说，所以大家潜意识里面人工智能是个虚幻的东西，它的载体是各种根本不存在的机器人：《星球大战》里面的，《黑客帝国》里面的，各种飞船的屏幕后面的。包括这几天下棋的新闻配图里面，大部分AlphaGo的形象都是个光头乳白色机器人。</p>

<p>但是也因为这次对弈，看到很多严肃的，人模人样的媒体和嘉宾都在讨论这个东西，看到一堆九段在直播间长吁短叹，大家就开始开玩笑地说：”完了完了，人类这是真的要完了“。</p>

<p>的确，简单地觉得DeepMind这种多层深度神经网络只是计算能力堆上来了而已，肯定是不对的。其实当年深蓝下赢卡斯帕罗夫的时候，当事人卡斯帕罗夫就有过一些好玩的言论：1995年他还在说计算机没有<code>insights</code>，到了1996年他就已经说感觉电脑有悟性了，到了1997年，他就输了，然后他觉得机器表现的智能无法理解，甚至怀疑有人类棋手在背后操作。</p>

<p>其实从1995到1997，深蓝的计算能力只增加了两倍而已。</p>

<p>这次围棋对弈的情况更加有趣：卡斯帕罗夫三年的心路历程，演播厅里面在前三十分钟嘲笑AlphaGo的围棋选手们几个小时就走完了。</p>

<p>所以我想，普通人关心的应该有下面几点：</p>

<ol>
<li>人工智能和人类智慧究竟有没有一点点可比性？</li>
<li>如果有，究竟发展到什么阶段了呢？</li>
<li>既然发展到这里了，奇点到底存不存在？人类要不要完呢？</li>
</ol>


<p>因为前面太啰嗦，这部分我们还是等一年一度的CCTV用消费者权益敲诈日结束之后再来写吧。</p>
]]></content>
  </entry>
  
</feed>
